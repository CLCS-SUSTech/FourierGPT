{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(spectrum_data_file: str, interp_len: int = 500):\n",
    "    df = pd.read_csv(spectrum_data_file)\n",
    "    # If `sid` column does not exist, create it\n",
    "    if 'sid' not in df.columns:\n",
    "        df['sdiff']  = df['freq'] < df['freq'].shift(1, fill_value=0)\n",
    "        df['sdiff'] = df['sdiff'].astype(int)\n",
    "        df['sid'] = df['sdiff'].cumsum()\n",
    "\n",
    "    features_interp = []\n",
    "    for _, group in df.groupby('sid'):\n",
    "        freqs = group['freq'].values\n",
    "        features = group['power'].values\n",
    "        new_freq = np.linspace(0, 0.5, interp_len)\n",
    "        new_feat = np.interp(new_freq, freqs, features)\n",
    "        features_interp.append(new_feat)\n",
    "\n",
    "    return np.array(features_interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8        0.78333333 0.8        0.83333333 0.8       ]\n",
      "0.8033333333333335\n"
     ]
    }
   ],
   "source": [
    "# GPT2-xl\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55       0.53333333 0.45       0.46666667 0.51666667]\n",
      "0.5033333333333333\n"
     ]
    }
   ],
   "source": [
    "# GPT2-lg\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.gpt2lg.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.gpt2lg.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46666667 0.51666667 0.51666667 0.55       0.55      ]\n",
      "0.5199999999999999\n"
     ]
    }
   ],
   "source": [
    "# GPT2-md\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.gpt2md.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.gpt2md.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.63333333 0.48333333 0.43333333 0.53333333]\n",
      "0.5166666666666666\n"
     ]
    }
   ],
   "source": [
    "# GPT2 \n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.gpt2.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.gpt2.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83333333 0.75       0.76666667 0.76666667 0.76666667]\n",
      "0.7766666666666666\n"
     ]
    }
   ],
   "source": [
    "# Mistral\n",
    "# x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.mistral.nlllogzs.fftnorm.circlemean.txt')\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.mistral.nllzs.fftnorm.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "# x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.mistral.nlllogzs.fftnorm.circlemean.txt')\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.mistral.nllzs.fftnorm.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81666667 0.75       0.78333333 0.78333333 0.75      ]\n",
      "0.7766666666666666\n"
     ]
    }
   ],
   "source": [
    "# Llama\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.llama.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.llama.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.71666667 0.73333333 0.78333333 0.73333333]\n",
      "0.7433333333333334\n"
     ]
    }
   ],
   "source": [
    "# Llama-13b\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.llama-13b.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.llama-13b.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48333333 0.63333333 0.45       0.51666667 0.56666667]\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "# GPT2-md-pubmed\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.gpt2md-pubmed.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.gpt2md-pubmed.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48333333 0.56666667 0.55       0.55       0.46666667]\n",
      "0.5233333333333334\n"
     ]
    }
   ],
   "source": [
    "# GPT2xl, questions shuffled\n",
    "x_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.questionshuffled.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.questionshuffled.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.61666667 0.7        0.7        0.7       ]\n",
      "0.6766666666666665\n"
     ]
    }
   ],
   "source": [
    "# GPT2-xl\n",
    "x_orig = get_features('../data/gpt-4/writing_gpt-4.original.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/writing_gpt-4.sampled.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.51666667 0.63333333 0.6        0.56666667]\n",
      "0.5966666666666667\n"
     ]
    }
   ],
   "source": [
    "# GPT2-lg\n",
    "x_orig = get_features('../data/gpt-4/writing_gpt-4.original.gpt2lg.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/writing_gpt-4.sampled.gpt2lg.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53333333 0.48333333 0.6        0.55       0.61666667]\n",
      "0.5566666666666668\n"
     ]
    }
   ],
   "source": [
    "# GPT2-md\n",
    "x_orig = get_features('../data/gpt-4/writing_gpt-4.original.gpt2md.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/writing_gpt-4.sampled.gpt2md.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56666667 0.58333333 0.61666667 0.55       0.56666667]\n",
      "0.5766666666666665\n"
     ]
    }
   ],
   "source": [
    "# GPT2 \n",
    "x_orig = get_features('../data/gpt-4/writing_gpt-4.original.gpt2.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/writing_gpt-4.sampled.gpt2.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65       0.63333333 0.6        0.65       0.61666667]\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "# Mistral\n",
    "x_orig = get_features('../data/gpt-4/writing_gpt-4.original.mistral.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/writing_gpt-4.sampled.mistral.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65       0.68333333 0.58333333 0.55       0.6       ]\n",
      "0.6133333333333334\n"
     ]
    }
   ],
   "source": [
    "# Llama\n",
    "x_orig = get_features('../data/gpt-4/writing_gpt-4.original.llama.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/writing_gpt-4.sampled.llama.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73333333 0.66666667 0.65       0.73333333 0.75      ]\n",
      "0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "# GPT2-xl\n",
    "x_orig = get_features('../data/gpt-4/xsum_gpt-4.original.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/xsum_gpt-4.sampled.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63333333 0.61666667 0.65       0.61666667 0.63333333]\n",
      "0.63\n"
     ]
    }
   ],
   "source": [
    "# GPT2 \n",
    "x_orig = get_features('../data/gpt-4/xsum_gpt-4.original.gpt2.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/xsum_gpt-4.sampled.gpt2.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199/199 [00:05<00:00, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 93\n",
      "Best avg score: 0.6533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mistral\n",
    "x_orig = get_features('../data/gpt-4/xsum_gpt-4.original.mistral.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "x_samp = get_features('../data/gpt-4/xsum_gpt-4.sampled.mistral.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "best_k = 1\n",
    "best_model = None\n",
    "best_avg_score = 0\n",
    "\n",
    "for k in tqdm(range(1, 200)):\n",
    "    model = make_pipeline(StandardScaler(),\n",
    "                        SelectKBest(k=k),\n",
    "        SVC(gamma='auto', kernel='rbf', C=1))\n",
    "    scores = cross_val_score(model, x, y, cv=5)\n",
    "    avg_score = np.mean(scores)\n",
    "    if avg_score > best_avg_score:\n",
    "        best_avg_score = avg_score\n",
    "        best_k = k\n",
    "        best_model = model\n",
    "\n",
    "print('Best k:', best_k)\n",
    "print('Best avg score:', best_avg_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
